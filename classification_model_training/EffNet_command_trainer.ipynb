{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MobileNetv2.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udTSIfIHmdCC",
        "outputId": "94ebc258-51e6-4d38-b1f8-5630bb84a7f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Apr 23 20:48:04 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   72C    P8    35W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        " \n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "COLAB = True\n",
        "print(\"Note: using Google CoLab\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtvUFXf0nulg",
        "outputId": "f72e9a7d-2aab-4e89-bd49-a52e38706407"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Note: using Google CoLab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install efficientnet_pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhevEZHsrPpO",
        "outputId": "a70317c2-d7d1-413a-82ae-0636c121f80c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting efficientnet_pytorch\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from efficientnet_pytorch) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->efficientnet_pytorch) (4.1.1)\n",
            "Building wheels for collected packages: efficientnet-pytorch\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16446 sha256=5d8077f31b3eaa7faa47438e11fc7c6e1e2d87dc90f05c92974f3727c5d64a9c\n",
            "  Stored in directory: /root/.cache/pip/wheels/0e/cc/b2/49e74588263573ff778da58cc99b9c6349b496636a7e165be6\n",
            "Successfully built efficientnet-pytorch\n",
            "Installing collected packages: efficientnet-pytorch\n",
            "Successfully installed efficientnet-pytorch-0.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/MyDrive/Makeathon_TUM/CoVision/classification_model_training/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTVVf09loBzG",
        "outputId": "129fa0c0-ff02-428d-be6e-76fb644b8142"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Makeathon_TUM/CoVision/classification_model_training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNMB-FAYn0ZQ",
        "outputId": "176b7971-3518-43bb-e40e-8e2ecca49c79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "helper_funcs.ipynb  \u001b[0m\u001b[01;34mOutput_path\u001b[0m/  predict.py  train.py  \u001b[01;34mutils\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "ylLKhdp-gmkp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATH_IMG = \"/content/drive/MyDrive/Makeathon_TUM/data/rapid_test_three_class_classification/train/images\"\n",
        "PATH_GT = \"/content/drive/MyDrive/Makeathon_TUM/data/rapid_test_three_class_classification/train/train.csv\"\n",
        "PATH_EXP = \"/content/drive/MyDrive/Makeathon_TUM/data/rapid_test_three_class_classification/experiments/03\"\n",
        "\n",
        "!python train.py --num_classes 3 --pretrained_on_ImageNet --fold 1 --dataset {PATH_IMG} --gt {PATH_GT} --outdir {PATH_EXP}  --epochs 30"
      ],
      "metadata": {
        "id": "9liZ9h7ToQXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "O6SiIRBPHBGK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATH_TEST_IMG = \"/content/drive/MyDrive/Makeathon_TUM/data/rapid_test_three_class_classification/test/images\"\n",
        "PATH_TEST_GT = \"/content/drive/MyDrive/Makeathon_TUM/data/rapid_test_three_class_classification/test/test.csv\"\n",
        "MODEL = \"/content/drive/MyDrive/Makeathon_TUM/data/rapid_test_three_class_classification/experiments/02/model_fold_1_20.pt\"\n",
        "\n",
        "\n",
        "!python predict.py --num_classes 3 --single_model_path {MODEL} --dataset {PATH_TEST_IMG} --gt {PATH_TEST_GT} "
      ],
      "metadata": {
        "id": "1TVK0RwHHB3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction on single image"
      ],
      "metadata": {
        "id": "aWxKfINFhKAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import cv2\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import numpy as np \n",
        "\n",
        "from PIL import Image\n",
        "from PIL import ImageFile"
      ],
      "metadata": {
        "id": "JrrtEW0OpoBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from efficientnet_pytorch import EfficientNet\n",
        "import torch\n",
        "import numpy as np\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from torch.autograd import Variable\n",
        "\n",
        "model_path = r\"/content/drive/MyDrive/Makeathon_TUM/data/rapid_test_classification/experiments/01/model_fold_1_5.bin\"\n",
        "\n",
        "model = EfficientNet.from_name(\"efficientnet-b2\", in_channels = 3, num_classes = 1)\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "model.to(\"cpu\")"
      ],
      "metadata": {
        "id": "naDPVVjnhJv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path_1 = r\"/content/drive/MyDrive/Makeathon_TUM/data/rapid_test_classification/cropped/test/images/test_negative_8.jpg\"\n",
        "image_path_2 = r\"/content/drive/MyDrive/Makeathon_TUM/data/rapid_test_classification/cropped/test/images/test_positive_9.jpg\"\n",
        "\n",
        "model.eval()\n",
        "\n",
        "loader = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()])\n",
        "\n",
        "def image_loader(image_name):\n",
        "    \"\"\"load image, returns cuda tensor\"\"\"\n",
        "    image = Image.open(image_name)\n",
        "    image = loader(image).float()\n",
        "    image = Variable(image, requires_grad=True)\n",
        "    image = image.unsqueeze(0)  #this is for VGG, may not be needed for ResNet\n",
        "    # return image.cuda()  #assumes that you're using GPU\n",
        "    return image\n",
        "\n",
        "image = image_loader(image_path_2)\n",
        "\n",
        "output = model(image)\n",
        "output = torch.sigmoid(output)\n",
        "\n",
        "print()\n",
        "print(\"output: \", output)\n",
        "print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2iO08WDhVpQ",
        "outputId": "660f4abd-2a37-4961-e726-2a1f136bc715"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "output:  tensor([[0.9997]], grad_fn=<SigmoidBackward0>)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert to Onnx and than to tf.js"
      ],
      "metadata": {
        "id": "LrOSgO3vMZRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert .bin to onnx"
      ],
      "metadata": {
        "id": "0QNI_PQfNSv0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch \n",
        "from efficientnet_pytorch import EfficientNet\n",
        "from torch.autograd import Variable\n",
        "import os\n",
        "\n",
        "model = EfficientNet.from_name(\"efficientnet-b2\", in_channels = 3, num_classes = 3)\n",
        "model.load_state_dict(torch.load(MODEL))\n",
        "model.set_swish(memory_efficient=False)\n",
        "\n",
        "dummy_input = Variable(torch.rand(1, 3, 224, 224))\n",
        "torch.onnx.export(model, dummy_input, os.path.join(PATH_EXP, \"best_model.onnx\"))"
      ],
      "metadata": {
        "id": "u-g312KIKFvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert .onnx to tensorflow saved model"
      ],
      "metadata": {
        "id": "vGxmpFv6NV5j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx-tf"
      ],
      "metadata": {
        "id": "bf2GdAXGNZHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_MODEL = os.path.join(PATH_EXP, \"best_model.onnx\")\n",
        "OUTPUT_MODEL = os.path.join(PATH_EXP, \"best_model.pb\")\n",
        "\n",
        "\n",
        "import onnx\n",
        "from onnx_tf.backend import prepare\n",
        "\n",
        "onnx_model = onnx.load(INPUT_MODEL)  # load onnx model\n",
        "tf_rep = prepare(onnx_model)  # prepare tf representation\n",
        "tf_rep.export_graph(OUTPUT_MODEL)  # export the model\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CvPIaRHNev1",
        "outputId": "edfa5c21-8c2f-46b6-a81e-55db20d908d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `__call__` contains input name(s) input.1 with unsupported characters which will be renamed to input_1 in the SavedModel.\n",
            "WARNING:absl:Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Makeathon_TUM/data/rapid_test_three_class_classification/experiments/03/best_model.pb/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Makeathon_TUM/data/rapid_test_three_class_classification/experiments/03/best_model.pb/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensorflow saved model to tf.js"
      ],
      "metadata": {
        "id": "bxsVk3nERQHk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflowjs"
      ],
      "metadata": {
        "id": "rd5R6ySvR-_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tensorflowjs_converter \\\n",
        "    --input_format=tf_saved_model \\\n",
        "    --output_node_names=tfjs_layers_model \\\n",
        "    --saved_model_tags=serve \\\n",
        "    /content/drive/MyDrive/Makeathon_TUM/data/rapid_test_three_class_classification/experiments/03/best_model.pb \\\n",
        "    /content/drive/MyDrive/Makeathon_TUM/data/rapid_test_three_class_classification/experiments/03/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMWY2l7GSRNj",
        "outputId": "b32b6a35-c3ca-41b8-f018-f8c9b2529897"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-04-24 00:39:43.565063: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "Writing weight file /content/drive/MyDrive/Makeathon_TUM/data/rapid_test_three_class_classification/experiments/03/model.json...\n"
          ]
        }
      ]
    }
  ]
}